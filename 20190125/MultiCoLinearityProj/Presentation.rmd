---
title: "本当はコワい線形回帰"
author: "Kien Knot @ TokyoR"
date: "2020/1/25"
output:   
  ioslides_presentation:
    widescreen: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)

```
# 改め
# Rが教えてくれたもの　　　　　　　そして教えてくれないもの

## 誰？

- [きぬいと](https://twitter.com/0_u0)
  - TokyoRで毎月発表してたような人。
  
- 調査屋さんのアナリスト

- 趣味
  - 簡単なことを難しく考える

- 今年もよろしく
  - 統計検定1級を取りに行きたい

# 今日のテーマは「決める」

## 人間は「人生の分かれ道」に立ちがち

- 受験「そっか、じゃあ卒業したら、別々の大学だね……」

- 就活「そっか、東京、いっちゃうんだ……」

- 転職「そっか、この会社やめちゃうんだね……」

- 結婚「結婚したのか……俺以外のやつと」

## そして迷いがち
- どの選択が「良い」のかわからない
- 「こっちが良さそう」って誰かに言ってほしい
  - そんな都合のいい存在はない。

- そもそも「良い」って何……？
  - 人生って何……？
  - 生きるとは……？
  
- どんどん思考がRegression。

# Regression？

## 「意思決定」のための回帰分析

- 回帰分析の結果を意思決定に使う話
  - 回帰係数見れば世界のすべてがわかるらしい
  - 昨今知られる機械学習と比べると「ホワイトボックス」らしい
  

- 前提知識: 回帰分析が分かれば大丈夫
  - 回帰**係数**が分かれば大丈夫
  - でも簡単じゃない話

## 統計モデルによる「意思決定」の話
- 生きる意味、持ってますか？
  - 家族、仕事、友達、R……
  - 自分の生きがいに一番寄与するものを探したい

- 回帰分析で評価・意思決定しよう。
  - どの変数が効くかな？
    - その変数を生きがいに生きていこう
  - 「効いている」の基準: p-value?
  

## データ
- ないのでつくりました。
```{r echo = TRUE}
set.seed(1234)                       # お気持ちの種
n <- 1000                            # 人
noise <- rnorm(n, mean=0, sd = 0.01) # 気持ちのゆらぎ

X1 <- rnorm(n, mean = 0, sd = 1)     # R言語を触ることによる高揚感
X2 <- rpois(n, lambda = 2)           # 今までに買ったマンガの冊数
X3 <- rnorm(n, mean = 5, sd = 5)     # 美術館の企画展を見たときの感情指数
X4 <- X1 + noise                     # Pythonを触ることによる高揚感
#cor(X1, X4)                          # 伏線
# 生きがいスコア
y <- 1.2 * X1 + 0.6 * X2 + 0.3 * X3 + rnorm(n, 0, 1) # 
```

## ダミーデータ
- データフレームにまとめる

```{r echo = TRUE}
UseData <- data.frame(IKIGAI          =  y,
                      R_usage         = X1,
                      MANGA_count     = X2,
                      Museum_emotion  = X3,
                      Python_usage    = X4)
```
- このデータに回帰分析を適用する

## きぬいとの生きがいとは……
- これで決まる
```{r echo=TRUE}
y <- 1.2 * X1 + 0.6 * X2 + 0.3 * X3 + rnorm(n, 0, 1) #iid
```
- 心の声「生きがいはRとマンガと美術館じゃね？」
  - `tidymodels`がきぬいとの中ではアツい
  - 最近のマンガでは『空挺ドラゴンズ』がアツいですよ。
  - ブダペスト展、アツいですね。



## 回帰分析してみましょう
- Rでやるには`lm()`関数。
  - `lm_model1`: `R_usage`、`MANGA_count`、`Museum_emotion`のみをつかう

- でもPythonのことが気になって仕方がない
  - ついつい投入してしまう
  - `lm_model2`: `Python_usage`をくわえてみる

```{r echo = TRUE}
lm_model1 <- lm(IKIGAI ~   R_usage       + 
                           MANGA_count   +
                           Museum_emotion,
                           data = UseData)
lm_model2 <- lm(IKIGAI ~ ., data = UseData)
```


## `lm_model1`の結果
- `Estimate`と`Pr(>|t|)`を確認する
```{r echo = TRUE}
summary(lm_model1)$coefficients
```

- `1.2 * X1 + 0.6 * X2 + 0.3 * X3 + rnorm(n, 0, 1)`に近い
  - ブレはほぼ標準誤差(`Std.Error`)範囲内。
  - p-valueもほぼ0。統計的に有意な結果。
  
## `lm_model2`の結果
- `Estimate`と`Pr(>|t|)`を確認する
```{r echo = TRUE}
summary(lm_model2)$coefficients
```
- `R_usage`のスコア(上手く推定できていたら1.2)が変
  - 標準誤差も大きく、統計的にも有意じゃない……
  - 「RもPython生きがいじゃない」……？
  
## かなしい
- 選ばれた生きがい
  - うず高く積まれたマンガに囲まれ
  - 週末は美術館に行く

- 充実していなくはない
  - でもなぜか心に穴がぽっかり空いてしまった

# BAD END

## 原因は？
- 原因は**多重共線性**
  - 説明変数の中に、互いに相関の強い項目があった
```{r echo=TRUE}
cor(X1, X4) # 伏線回収
```
  - きぬいとはRもPythonも好きだった……
  - 結果推定値の標準誤差がでかくなり有意性を失う。

- 本来必要なはずの変数
  - p-valueを基準に選ぶと失敗する(こともある)
  - データを多角的にみてあげよう
  - 「回帰係数で変数の影響度解釈していいの？」という話はまた別の機会に。
  
## まとめ
- **Rは優しい**から結果は簡単に出してくれる。
  - でも**結果の妥当性**までは教えてくれない
  - 結果を疑おう。
    - ちょっと考えれば**RもPythonも等しく愛せること**に気付けるはず
  
- p-valueを過信しないようにしよう
  - 意味がある変数が有意になるとは限らない
    - 「回帰係数は0じゃないことはわかる」だけ。
    
- 生きがいを探そう

## Enjoy!
- 何かを決めるのは難しい
  - 難しいけど[Wantedly貼っとくわ](https://www.wantedly.com/users/70198846)

- 真面目な話をしてしまった
  - この先の話は[ブログで書いた](http://socinuit.hatenablog.com/entry/2019/12/21/042023)
  - 正則化回帰の話も[ブログで書いた](http://socinuit.hatenablog.com/entry/2019/12/19/132851)
  - Lasso楽しい[ブログも書いた](http://socinuit.hatenablog.com/entry/2019/12/06/015140)
  - 次があれば面白い話をします
