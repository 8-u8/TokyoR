---
title: "本当はコワい線形回帰"
author: "Kien Knot @ TokyoR"
date: "2020/1/25"
output: ioslides_presentation
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)

```

## 誰？
- [きぬいと](https://twitter.com/0_u0)
  - TokyoRで毎月発表してたような人。
  
- 調査屋さんのアナリスト
  - 主なお仕事: 統計モデリング
    - 予測もそう
    - 分類もそう
    - 説明モデルもそう

- 主な仕事
  - 簡単なことを難しく考える

- 今年もよろしく
  - 統計検定1級を取りに行きたい

# 今日のお話

## みんなー！「意思決定」支援してる？
- 回帰分析の結果を意思決定に使う話
  - なんか「ホワイトボックス」らしい
  - 回帰係数見ればわかるらしい

- 前提知識: 回帰分析が分かれば大丈夫
  - 回帰**係数**が分かれば大丈夫
  - でも簡単じゃない話

## 統計モデルによる「意思決定」の話
- KPI、ありますか？
  - 売上、売上増分、ユーザ数推移……
  - 予測したり、要因を見極めたりしたい。

- 回帰分析で評価・意思決定しよう。
  - どの変数が効くかな？
    - その変数を伸ばせるような施策を打とう
  - 「効いている」の基準: p-value?
  
## ダミーデータ
- こんな感じのデータを作る。
  - ダミーデータなので好きに想像してください
```{r echo = TRUE}
set.seed(1234)
n <- 1000
X1 <- rnorm(n, mean = 0, sd = 1) # 例えばサイトでの商品購入金額とか
X2 <- rpois(n, lambda = 2)       # 例えば会員の直近のサイト訪問回数とか
X3 <- rnorm(n, mean = 5, sd = 5) # 例えばサイト行動指標とか
noise <- rnorm(n, mean=0, sd = 0.01) # お気持ちノイズ
X4 <- X1 + noise                 # 例えばサイトでの購入商品個数とか
cor(X1, X4)
# 例えば顧客ロイヤリティスコアみたいな
y <- 1.2 * X1 + 0.6 * X2 + 0.3 * X3 + rnorm(n, 0, 1) #iid
```

## ダミーデータ
- データフレームにまとめる
  - `target`   : 目的変数(売上とかユーザ数とか顧客満足度とか)
  - `feature_x`: 説明変数(サイト来訪有無とか、広告反応有無とか)
```{r echo = TRUE}
UseData <- data.frame(target = y, feature_1 = X1,
                      feature_2 = X2,feature_3 = X3,feature_4 = X4)
```
- このデータに回帰分析を適用する

## 今回の目的変数は……
- これで決まる
```{r echo=TRUE}
y <- 1.2 * X1 + 0.6 * X2 + 0.3 * X3 + rnorm(n, 0, 1) #iid
```
- つまり、`feature_1`、`feature_2`、`feature_3`で決まる
    - 例えばロイヤリティはサイト購入金額と訪問回数と行動指標で決まる

- でも購入商品個数も効きそうだし入れようって思いがちじゃん？
  - 使ってみような

## 回帰分析してみましょう
- Rでやるには`lm()`関数。
  - `lm_model1`: `feature_1`、`feature_2`、`feature_3`のみをつかう
  - `lm_model2`: `feature_4`をくわえてみる
```{r echo = TRUE}
lm_model1 <- lm(target ~ feature_1 + feature_2 + feature_3,
                data = UseData)
lm_model2 <- lm(target ~ ., data = UseData)
```
- 結果が`feature_1`、`feature_2`、`feature_3`で説明できればOK
  - この3つの変数が「統計的に有意」ならちゃんと推定できている

## `lm_model1`の結果
- `Estimate`と`Pr(>|t|)`を確認する
```{r echo = TRUE}
summary(lm_model1)$coefficients
```

- `1.2 * X1 + 0.6 * X2 + 0.3 * X3 + rnorm(n, 0, 1)`に近い
  - ブレはほぼ標準誤差(`Std.Error`)範囲内。
  - p-valueもほぼ0。統計的に有意な結果。
  
## `lm_model2`の結果
- `Estimate`と`Pr(>|t|)`を確認する
```{r echo = TRUE}
summary(lm_model2)$coefficients
```
- `feature_1`のスコア(上手く推定できていたら1.2)が変
  - 標準誤差も大きく、統計的に有意じゃない……
  
## なんで？？
- 原因は**多重共線性**
  - 説明変数の中に、互いに相関の強い項目があった
  - 今回`X4 <- X1 + noise`で定義。高い相関がある

- 本来KPIを説明するのに必要なはずの変数
  - p-valueを基準に選ぶと失敗する。
  - データを抜き差ししてAUCとかR-squareがどれだけ落ちるかを見るなどしよう
  
## これがどんなときに危ない？
- 本来KPIにそれなりの寄与をしている変数を 「寄与していない」と切り捨ててしまうリスク
  - 例えば意思決定は「セールをする」方が有効なはず
    - なのにコストをかけてサイトリニューアルをしてしまう。
  - 結果予測よりもロイヤリティスコアが上がらなかった(フィクション)
  - ROIがやばい
  
- 回帰分析は回帰係数の存在が便利
  - でもその係数本当に「妥当」ですか？
  - いろんなバイアス・罠がある
  - ただ回した結果で議論するのは実際危険

## まとめ
- **Rは優しい**から結果は簡単に出してくれる。
  - でも**結果の妥当性**までは教えてくれない
  - 結果を疑おう。
    - どうしてこうなった
    - ちょっと考えれば金額と個数の相関は気づける(はず)
  
- 説明変数の間の相関には気をつけよう
  - 相関行列は必ず見よう
  - VIFとか見よう(詳しくはググってね)

- p-valueを過信しないようにしよう
  - 意味がある変数が有意になるとは限らない
    - 「回帰係数は0じゃないことはわかる」だけ。

## Enjoy!
- 真面目な話をしてしまった
  - [この先の話はブログで書いた](http://socinuit.hatenablog.com/entry/2019/12/21/042023)
  - [正則化回帰の話もブログで書いた](http://socinuit.hatenablog.com/entry/2019/12/19/132851)
  - [Lasso楽しいブログも書いた](http://socinuit.hatenablog.com/entry/2019/12/06/015140)
  - 次があれば面白い話をします
